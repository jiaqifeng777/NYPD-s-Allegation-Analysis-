{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "In this project, I will build a model to predict the outcome of an allegation. As \"outcome_descroption\" in the data is a nominal variable, I treat my prediction problem as a classification problem, that is, classifying different outcomes based on selected features and then make predictions. The evaluation metric I choose for my model is the accuracy. This is because the aim of improving my model is to increase the proportin of predictions that are correct, so I will treat all correct/incorrect guesses equally.\n",
    "\n",
    "\n",
    "### Baseline Model\n",
    "In my baseline model, I use RandomForestClassifier and include 3 generic features that I think would most likley to affect the outcome\n",
    "\n",
    "1.1 \"rank_incident\": ordinal\n",
    "- Police with higher ranks are more experienced, so that they may be less likely to have severe misconduct, and thus the outcome of the complaints they received may be more positive than those in lower ranks. \n",
    "\n",
    "\n",
    "1.2 \"mos_gender\": nominal\n",
    "- There may be some tendencies when making the sanction for police in different gender groups. For example, police in certain gender group may be less likely to sanctioned as misconduct by NYPD at the end\n",
    "\n",
    "\n",
    "1.3 \"open_length\": quantitative\n",
    "- Complaints with shorter open length may be decided more easily, so that they are more likely to fall into similar outcomes categories, so open length may indicate the outcome.\n",
    "\n",
    "\n",
    "The average R^2 of my baseline model is about 0.390. The baseline model only explains 38.9% of the variablility of the response variable. The accuracy of the baseline model is 0.388, which needs further improvements.\n",
    "\n",
    "### Final Model\n",
    "\n",
    "In my final model, I still use the RandomForestClassifier with the previous 3 features, but add 3 more engineered features:\n",
    "\n",
    "2.1 standard scaled \"open_length\" within differnet \"fado_type\" groups: quantitative\n",
    "- Different FADO types may also have different open length, so I standard scaled \"open_length\" within differnet \"fado_type\" groups.\n",
    "\n",
    "\n",
    "2.2 \"allegation\" is binned into several major categories: nominal\n",
    "- Different types of allegations may have an impact on the outcome. Some allegations may be more severe than others, so that the outcome may also be more severe. I binned some types of allegations into major ones to make the types more general.\n",
    "\n",
    "\n",
    "2.3 \"unique_mos_id\" is engineered to the number of times each one appears in records: quantitative\n",
    "- There may be police who often receive complaints, which may indicate they are more likely to have misconduct, so that they are more likely to receive more severe outcomes. So I incorporate the counts of the occurrence of each mos id in records.\n",
    "\n",
    "The average R^2 of my final model is about 0.434. And the accuracy of the final model is 0.431. The performance of my final model is better than that of the baseline model.\n",
    "\n",
    "I then use GridSearchCV to perform a search for the best model and parameters:\n",
    "\n",
    "- The average over the cross-validation fold scores of the best model is 0.438. \n",
    "\n",
    "- I find the best parameters for my model are: max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=12. \n",
    "\n",
    "- The resulting R^2 increases to 0.435. So now the final model explains 43.5% of the variability of the response variable. And the accuracy now also increases to 0.435.\n",
    "\n",
    "\n",
    "### Fairness Evaluation\n",
    "I want to explore whether my model is fairer for male police than female police, so I choose \"mos_gender\" to construct my interesting subset. I then split my subset into two subsets by \"mos_gender\" and run a permutation test with R^2 as the test statistics. This is because I care more about how my model fits the data in female and male police subset, or whether it is biased (more well-fitted) to a gender.\n",
    "\n",
    "Permutation test with the significance level of 95%:\n",
    "\n",
    "- Null Hypothesis: My model is fair, and the R^2 for my two subsets are roughly the same\n",
    "- Alternative Hypothesis: My model is unfair, and the R^2 for the male subset is higher than the female subset\n",
    "\n",
    "I get a p-value of 0.81 > 0.05 from my permutation test, so I fail to reject the null hypothesis and it is very likely that my model is fair on different genders of the police."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/allegations_202007271729.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace unknown with null values\n",
    "df = df.replace('Unknown', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine receive date related columns to create datetime object for receive date\n",
    "receive = df[['month_received', 'year_received']]\n",
    "receive = receive.rename(columns = {'month_received' : 'month' , 'year_received' : 'year'})\n",
    "receive = receive.assign(day = 1)\n",
    "receive_date = pd.to_datetime(receive[[\"month\", \"year\",\"day\"]])\n",
    "df = df.assign(receive_date = receive_date)\n",
    "\n",
    "# Combine close date related columns to create datetime object for close date\n",
    "close = df[['month_closed', 'year_closed']]\n",
    "close = close.rename(columns = {'month_closed' : 'month' , 'year_closed' : 'year'})\n",
    "close = close.assign(day = 1)\n",
    "close_date = pd.to_datetime(close[[\"month\", \"year\",\"day\"]])\n",
    "df = df.assign(close_date = close_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the length of open time for each complaint based on \"receive_date\" and \"close_date\", \n",
    "# and add a column \"open_length\" to the dataset:\n",
    "df = df.assign(open_length = df['close_date'] - df['receive_date'])\n",
    "df.open_length = df.open_length.dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only incorporate 3 generic features that I think are most likely to affect the outcome:\n",
    "1. \"rank_incident\": ordinal\n",
    "2. \"mos_gender\": nomial\n",
    "3. \"open_length\": quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoding the rank of officers\n",
    "df['ordinal_rank_incident'] = df.rank_incident.map({'Police Officer':0, 'Detective':1, \n",
    "                                                    'Sergeant':2, 'Lieutenant':3,\n",
    "                                                    'Captain':4, 'Deputy Inspector':5, \n",
    "                                                    'Inspector':6, 'Chiefs and other ranks':7\n",
    "                                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build baseline model with these 3 features\n",
    "cats = Pipeline([\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown = 'ignore')), \n",
    "    ('pca', PCA(svd_solver='full'))\n",
    "])\n",
    "catcols = ['mos_gender']\n",
    "\n",
    "nums = Pipeline([('std_scaling', StandardScaler())])\n",
    "numcols = ['ordinal_rank_incident', 'open_length']\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('catcols', cats, catcols),\n",
    "    ('numcols', SimpleImputer(strategy='constant', fill_value=0), numcols)\n",
    "])\n",
    "\n",
    "pl = Pipeline([('feats', ct), \n",
    "               ('classifier', RandomForestClassifier(max_depth=10,\n",
    "                                                           min_samples_leaf=2, \n",
    "                                                           min_samples_split=2,\n",
    "                                                           n_estimators=5)\n",
    "               )\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39261102941176473"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features\n",
    "va_df = df.dropna(axis = 0)\n",
    "X = va_df[['open_length',\n",
    "           'ordinal_rank_incident', \n",
    "           'mos_gender'\n",
    "         ]]\n",
    "\n",
    "# outcome\n",
    "y = va_df.outcome_description\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "rsqr_lst = []\n",
    "for i in range(200):\n",
    "    pl.fit(X_train, y_train);\n",
    "    rsqr = pl.score(X_test, y_test)\n",
    "    rsqr_lst.append(rsqr)\n",
    "np.mean(rsqr_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 for my baseline model is only 0.390."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4314705882352941"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pl.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the baseline model is 0.388, which needs further improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I incorporate three more engineered features in the final model: \n",
    "1. \"open_length\" is standard scaled within differnet \"fado_type\" groups\n",
    "2. \"allegation\" is binned into several major categories\n",
    "3. \"unique_mos_id\" is enginnered as the number of times each one appears in records and save as \"id_cnt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design StdScalerByGroup Transformer for standard scaling \"open_length\"\n",
    "# within differnet \"fado_type\" groups\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class StdScalerByGroup(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> std.grps_ is not None\n",
    "        True\n",
    "        \"\"\"\n",
    "        # X may not be a pandas dataframe (e.g. a np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "\n",
    "        # A dictionary of means/standard-deviations for each column, for each group.\n",
    "        colname = df.columns\n",
    "        grp_mean = df.groupby(colname[0]).aggregate(np.mean)\n",
    "        grp_mean.columns = [i + '_mean' for i in grp_mean.columns]\n",
    "        grp_sd = df.groupby(colname[0]).aggregate(np.std)\n",
    "        grp_sd.columns = [i + '_sd' for i in grp_sd.columns]\n",
    "        \n",
    "        self.grps_ = pd.concat([grp_mean, grp_sd], axis = 1)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> out = std.transform(X)\n",
    "        >>> out.shape == (4, 2)\n",
    "        True\n",
    "        >>> np.isclose(out.abs(), 0.707107, atol=0.001).all().all()\n",
    "        True\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            getattr(self, \"grps_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "\n",
    "\n",
    "        # Define a helper function here?\n",
    "        def zscore (df, grp, col):\n",
    "            mean = self.grps_.loc[grp, col + '_mean']\n",
    "            sd = self.grps_.loc[grp, col + '_sd']\n",
    "            df.loc[grp, col] = df.loc[grp, col].apply(lambda x: (x - mean) / sd)\n",
    "\n",
    "        \n",
    "        # X may not be a dataframe (e.g. np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "        colname = df.columns\n",
    "        grpcol = colname[0]\n",
    "        df = df.set_index(grpcol)\n",
    "        grps_name = df.index.unique()\n",
    "        cols_name = df.columns\n",
    "        for grp in grps_name:\n",
    "            for col in cols_name:\n",
    "                zscore(df, grp, col)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to bin \"allegation\" into several major categories\n",
    "\n",
    "def categorize_alle(alle): \n",
    "    if alle in ['Word', 'Threat of arrest']:\n",
    "        cate = 'Word'\n",
    "    elif alle in ['Stop', 'Vehicle stop']:\n",
    "        cate = 'Stop'\n",
    "    elif alle in ['Search (of person)', 'Frisk', 'Vehicle search']:\n",
    "        cate = 'Search'\n",
    "    elif alle in ['Premises entered and/or searched', 'Refusal to provide name/shield number']:\n",
    "        cate = 'Special'    \n",
    "    else:\n",
    "        cate = 'Force'\n",
    "    return cate\n",
    "\n",
    "\n",
    "def cate_on_alle(alle_col):\n",
    "    df = pd.DataFrame(alle_col)\n",
    "    df.allegation = df.allegation.apply(lambda x: categorize_alle(x))\n",
    "    return df\n",
    "\n",
    "# Add the binned allegation back to dataframe\n",
    "df['binned_alle'] = cate_on_alle(df.allegation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column that contains counts of each id in \"unique_mos_id\" column\n",
    "id_cnt = dict(df.unique_mos_id.value_counts())\n",
    "df['id_cnt'] = df.unique_mos_id.apply(lambda x: id_cnt[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = Pipeline([\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown = 'ignore')), \n",
    "    ('pca', PCA(svd_solver='full'))\n",
    "])\n",
    "catcols = ['mos_gender', 'binned_alle']\n",
    "\n",
    "nums = Pipeline([('std_scaling', StandardScaler())])\n",
    "numcols = ['ordinal_rank_incident', 'id_cnt',]\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('StdScaler', StdScalerByGroup(), ['fado_type', 'open_length']),\n",
    "    ('catcols', cats, catcols),\n",
    "    ('numcols', SimpleImputer(strategy='constant', fill_value=0), numcols)\n",
    "])\n",
    "\n",
    "pl = Pipeline([\n",
    "               ('feats', ct),           \n",
    "               ('classifier', RandomForestClassifier(max_depth=10, \n",
    "                                                     min_samples_leaf=2, \n",
    "                                                     min_samples_split=2,\n",
    "                                                     n_estimators=5)\n",
    "               )\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "va_df = df.dropna(axis = 0)\n",
    "X = va_df[[\n",
    "           'ordinal_rank_incident',      \n",
    "           'mos_gender', \n",
    "           'fado_type', \n",
    "           'open_length',\n",
    "           'binned_alle',\n",
    "           'id_cnt'\n",
    "           \n",
    "           ]]\n",
    "\n",
    "# outcome\n",
    "y = va_df.outcome_description\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "   \n",
    "rsqr_lst = []\n",
    "for i in range(200):\n",
    "    pl.fit(X_train, y_train);\n",
    "    rsqr = pl.score(X_test, y_test)\n",
    "    rsqr_lst.append(rsqr)\n",
    "np.mean(rsqr_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average R^2 for my final model is only 0.434, so the model fits the data better than the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4314705882352941"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pl.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the final model is 0.431."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I perform a search for the best model parameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'classifier__max_depth': [10,13,15,17,19], \n",
    "    'classifier__min_samples_split':[5,7,9],\n",
    "    'classifier__min_samples_leaf':[5,7,9],\n",
    "    'classifier__n_estimators': [9,10,11,12,13]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = GridSearchCV(pl, param_grid=parameters, cv=4, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 15,\n",
       " 'classifier__min_samples_leaf': 5,\n",
       " 'classifier__min_samples_split': 5,\n",
       " 'classifier__n_estimators': 12}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.435"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the best parameters, R^2 of the model now increases to 0.435."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4375"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average over the cross-validation fold scores of the best model is 0.438."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.435"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = grids.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the final model with the best parameters is 0.435."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_bst = Pipeline([\n",
    "               ('feats', ct),           \n",
    "               ('classifier', RandomForestClassifier(max_depth=15, \n",
    "                                                     min_samples_leaf=5, \n",
    "                                                     min_samples_split=5,\n",
    "                                                     n_estimators=12)\n",
    "               )\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to explore whether my model is fairer for female police or male police, so I will choose \"mos_gender\" to construct my interesting subset. I then split my subset into two subsets by \"mos_gender\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = va_df[[\n",
    "           'ordinal_rank_incident', \n",
    "           'mos_gender', \n",
    "           'fado_type', \n",
    "           'open_length',\n",
    "           'binned_alle',\n",
    "           'id_cnt',\n",
    "           'outcome_description'    \n",
    "           ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my parity measure, I will pick R^2 as the objective and run a permutation test, I choose the significance level of 95%:\n",
    "- Null Hypothesis: My model is fair, and the R^2 for my two subsets are roughly the same\n",
    "- Alternative Hypothesis: My model is unfair, and the R^2 for the male subset is higher than the female subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 100\n",
    "\n",
    "differences = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # shuffle mos_gender\n",
    "    shuffled_gender = (\n",
    "        subdf['mos_gender']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # put them in a table\n",
    "    shuffled = (\n",
    "        subdf\n",
    "        .assign(**{'Shuffled Gender': shuffled_gender})\n",
    "    )\n",
    "    \n",
    "    # compute the R^2 of model on female and male subsets\n",
    "    F = shuffled[shuffled['Shuffled Gender'] =='F']\n",
    "    M = shuffled[shuffled['Shuffled Gender'] =='M']\n",
    "    \n",
    "    X_F = F[['ordinal_rank_incident', \n",
    "           'mos_gender', \n",
    "           'fado_type', \n",
    "           'open_length',\n",
    "           'binned_alle',\n",
    "           'id_cnt']]\n",
    "    y_F = F.outcome_description\n",
    "\n",
    "    X_M = M[['ordinal_rank_incident', \n",
    "               'mos_gender', \n",
    "               'fado_type', \n",
    "               'open_length',\n",
    "               'binned_alle',\n",
    "               'id_cnt']]\n",
    "    y_M = M.outcome_description\n",
    "    \n",
    "    X_F_train, X_F_test, y_F_train, y_F_test = train_test_split(X_F, y_F, test_size=0.25)\n",
    "    X_M_train, X_M_test, y_M_train, y_M_test = train_test_split(X_M, y_M, test_size=0.25)\n",
    "    \n",
    "    pl_bst.fit(X_F_train, y_F_train);\n",
    "    preds_F = pl_bst.predict(X_F_test)\n",
    "    FR2 = pl_bst.score(X_F_test, y_F_test)\n",
    "    \n",
    "    pl_bst.fit(X_M_train, y_M_train);\n",
    "    preds_M = pl_bst.predict(X_M_test)\n",
    "    MR2 = pl_bst.score(X_M_test, y_M_test)\n",
    "    \n",
    "    # diffenerce in R^2\n",
    "    diff = FR2 - MR2\n",
    "    \n",
    "    # add it to the list of results\n",
    "    differences.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06541224616890196"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observed difference of R^2 of model on female and male subsets\n",
    "F = subdf[subdf.mos_gender =='F']\n",
    "M = subdf[subdf.mos_gender =='M']\n",
    "X_F = F[['ordinal_rank_incident', \n",
    "           'mos_gender', \n",
    "           'fado_type', \n",
    "           'open_length',\n",
    "           'binned_alle',\n",
    "           'id_cnt']]\n",
    "y_F = F.outcome_description\n",
    "\n",
    "X_M = M[['ordinal_rank_incident', \n",
    "           'mos_gender', \n",
    "           'fado_type', \n",
    "           'open_length',\n",
    "           'binned_alle',\n",
    "           'id_cnt']]\n",
    "y_M = M.outcome_description\n",
    "\n",
    "X_F_train, X_F_test, y_F_train, y_F_test = train_test_split(X_F, y_F, test_size=0.25)\n",
    "X_M_train, X_M_test, y_M_train, y_M_test = train_test_split(X_M, y_M, test_size=0.25)\n",
    "\n",
    "pl_bst.fit(X_F_train, y_F_train);\n",
    "preds_F = pl_bst.predict(X_F_test)\n",
    "FR2 = pl_bst.score(X_F_test, y_F_test)\n",
    "\n",
    "pl_bst.fit(X_M_train, y_M_train);\n",
    "preds_M = pl_bst.predict(X_M_test)\n",
    "MR2 = pl_bst.score(X_M_test, y_M_test)\n",
    "\n",
    "obs = FR2 - MR2\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 382
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the observed differnce of R^2 with respect to the simulation result\n",
    "pd.Series(differences).plot(kind='hist', density=True, alpha=0.8)\n",
    "plt.scatter(obs, 0.01, color='red', s=40, zorder=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate p-value\n",
    "pval = np.count_nonzero(differences >= obs) / n_repetitions\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I get a p-value of 0.81, so that I fail to reject the null hypothesis and it is very likely that my model is fair on different genders of the police, since the R^2 for my two gender subsets are roughly the same from the simulation test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
